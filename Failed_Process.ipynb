{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNX9wGJ7/nLa6qJyOTWFko/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#1.Initial Approach\n","\n","To predict flight delays, we initially created classification models to categorize flights as \"delayed\", \"on-time\", or \"cancelled\" based on the 2013 historical flight data set. Using the target variable \"total_delay\" we set a threshold of 20 minutes; if the total_delay exceeded it, the flight would be classified as delayed and others on-time. We trained models such as Random Forests, Support Vectors Machines and Neural Networks to analyze key flight attributes such as departure time, airline carrier, origin, destination and historical delays.\n","\n","\n","\n","After trying various methods, we decided not to continue with this approach, as classification models oversimplified the problem by essentially reducing delays down to discrete categories rather finding the continuous nature of delays.\n","\n","\n","Instead, we shifted our focus on creating regression based models that can accurately predict delay duration, providing more insights for airlines and airports.\n","\n","#Next Steps:\n","Upon completing of both the regressors and classifiers models, we identified opportunites to enhance our regressors by incorporating additional data sources.\n","To improve the robustness of our predictions, we scraped weather data from the OpenWeatherMap API and integrated it into our dataset. By including weather related variables such as temperature, humidity, windspeed, and precipitation, we aimed to find what external factors significatly impact flight delays.\n","\n","\n","#Note:\n","In this Failed_Process.ipynb, we go through our initial process of creating classification and regression models before changing our approach in ITEC4305_Group_Project.ipynb\n","\n"],"metadata":{"id":"y5I_3acA7FWp"}},{"cell_type":"markdown","source":["#Classification Models\n","\n","The objective is creating various machine learning models / algorithms to test their precision recall, AUC-ROC, and f1-scores for predicting total delays to see which one classifies the greatest for flights greater then 20 minutes\n","\n","\n","\n","#Machine Learning Algorithms:\n","Random Forest Classifier\n","\n","Support Vector Machine (SVM) Classifier\n","\n","Feedforward Neural Network (FFNN)\n","\n","#Evaluation Metrics:\n","Precision: Measures the proportion of correctly predicted delayed flights out of all flights predicted as delayed.\n","\n","Recall: Measures the proportion of correctly predicted delayed flights out of all actual delayed flights.\n","\n","AUC-ROC: Evaluates the model's ability to distinguish between delayed and non-delayed flights across different thresholds.\n","\n","F1-Score: Combines precision and recall into a single metric, providing a balanced measure of model performance."],"metadata":{"id":"9QCBmrQEAonb"}},{"cell_type":"markdown","source":["# 1. Random Forest Classifier\n","About 1 minute runtime"],"metadata":{"id":"2J-mLXoqBPay"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score,recall_score\n","\n","\n","\n","df=pd.read_csv('flights_EDA.csv')\n","\n","X= df.drop(columns=['total_delay', 'id', 'time_hour', 'name', 'dep_delay', 'arr_delay'])\n","y=(df['total_delay']> 20).astype(int)\n","\n","\n","#list all the categorical columns and numerical\n","categorical_cols =['carrier', 'origin', 'dest', 'flight_status', 'flight', 'tailnum']\n","num_cols =['dep_time', 'arr_time', 'air_time', 'distance']\n","#spliting the data into training, test and validation\n","\n","X_train, X_temp, y_train, y_temp = train_test_split(X,y, test_size=0.3, random_state=1)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n","\n","#creating the preprocessing pipleine to train the model\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[('num', StandardScaler(), num_cols),\n","                  ('cat', OneHotEncoder(handle_unknown='ignore'),categorical_cols)]\n",")\n","\n","#create the pipeline\n","pipeline = Pipeline(steps=[\n","    ('preprpcessor', preprocessor),\n","    ('classifier', RandomForestClassifier(n_estimators=5, random_state=1))\n","])\n","\n","\n","\n"],"metadata":{"id":"oqzvsf2oAxTb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train the random forest classifier\n","pipeline.fit(X_train, y_train)\n","print('done training')\n"],"metadata":{"id":"VicN7IUYBXNe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Training the model on the validation set\n","given the results we can retrain or test the model on the test set to see if the model is performing well"],"metadata":{"id":"XJrBEpUtBX9I"}},{"cell_type":"code","source":["y_prediction = pipeline.predict(X_val)\n","#checking the metrics to see if retraining is needed\n","\n","print(f\"Accuracy: {accuracy_score(y_val, y_prediction):.4f}\")\n","print(f\"Classification report:\\n {classification_report(y_val, y_prediction)}\")\n","print(f\"\\nConfusion Matrix: {confusion_matrix(y_val, y_prediction)}\")\n","\n","y_prob = pipeline.predict_proba(X_val)[:,1] #calculating the probability of flight being delayed\n","print(f\"\\n AUC-ROC score: {roc_auc_score(y_val, y_prob):.4f}\")"],"metadata":{"id":"cfBt_vR0Bn4r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------------------------------------------------------------------\n","# Results\n","\n","The model demonstrates excellent performance, achieving an accuracy of 98.13% and an AUC-ROC score of 0.9965, indicating its strong ability to distinguish between delayed and non-delayed flights. The classification report shows high precision (0.97) and recall (0.95) for delayed flights (class 1), with an F1-score of 0.96, suggesting a balanced performance in identifying both classes. The confusion matrix further confirms the model's effectiveness, with only 341 false positives and 581 false negatives out of 49,209 samples. Overall, the model is highly reliable for predicting flight delays."],"metadata":{"id":"MnAo7iLFBt9w"}},{"cell_type":"markdown","source":["# 2. SVM Classifier\n","about 15 minute runtime"],"metadata":{"id":"ydp067E6BzIf"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n","\n","# Load the dataset\n","df = pd.read_csv('flights_EDA.csv')\n","\n","# Define features and target\n","X = df.drop(columns=['total_delay', 'id', 'time_hour', 'name', 'dep_delay', 'arr_delay'])\n","y = (df['total_delay'] > 20).astype(int)  # Binary classification target\n","\n","# List all categorical and numerical columns\n","categorical_cols = ['carrier', 'origin', 'dest', 'flight_status']  # Drop high-cardinality features\n","num_cols = ['dep_time', 'arr_time', 'air_time', 'distance']\n","\n","# Split the data into training, validation, and test sets\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=1)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n","\n","# Create the preprocessing pipeline\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), num_cols),  # Scale numerical features\n","        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)  # One-hot encode categorical features\n","    ]\n",")\n","\n","# Create the SVM pipeline with a linear kernel\n","svm_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),  # Preprocessing\n","    ('classifier', SVC(kernel='linear', probability=True, random_state=1))  # Linear SVM with parallel processing\n","])\n","\n","# Train the SVM model\n","svm_pipeline.fit(X_train, y_train)\n","print('SVM model training complete')\n","\n","# Evaluate on the validation set\n","y_val_pred = svm_pipeline.predict(X_val)\n","y_val_prob = svm_pipeline.predict_proba(X_val)[:, 1]  # Probabilities for ROC-AUC\n","\n","print(\"Validation Set Metrics:\")\n","print(f\"Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n","print(f\"Classification Report:\\n{classification_report(y_val, y_val_pred)}\")\n","print(f\"Confusion Matrix:\\n{confusion_matrix(y_val, y_val_pred)}\")\n","print(f\"ROC-AUC Score: {roc_auc_score(y_val, y_val_prob):.4f}\")\n","\n","# Evaluate on the test set\n","y_test_pred = svm_pipeline.predict(X_test)\n","y_test_prob = svm_pipeline.predict_proba(X_test)[:, 1]  # Probabilities for ROC-AUC\n","\n","print(\"\\nTest Set Metrics:\")\n","print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n","print(f\"Classification Report:\\n{classification_report(y_test, y_test_pred)}\")\n","print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_test_pred)}\")\n","print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_test_prob):.4f}\")"],"metadata":{"id":"4vq-DrGHB0Tf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------------------------------------------------------------------\n","# Results\n","\n","The SVM classifier delivers exceptional performance, achieving near-perfect metrics on both the validation and test sets. With an accuracy of 99.99% and a ROC-AUC score of 1.0000, the model demonstrates flawless classification capabilities. The classification report shows perfect precision, recall, and F1-scores (1.00) for both classes (0 and 1), indicating no misclassifications. The confusion matrix further confirms this, with only 3 false positives and 3 false negatives on the validation set, and 3 false positives and 2 false negatives on the test set. This outstanding performance makes the SVM classifier a highly reliable model for predicting flight delays.\n","\n","# Disclaimer:\n","We believe the data may be overfitting or the classification might be too easy considering the attributes it uses to classify properly."],"metadata":{"id":"SFruMXz_B92P"}},{"cell_type":"markdown","source":["# Training The Feed-Forward Neural Network Classifier\n","About 5-6 minute runtime"],"metadata":{"id":"WQ_ybuVkCBS0"}},{"cell_type":"code","source":["pip install scikit-optimize"],"metadata":{"id":"9Z9UH81-CLvx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n","import matplotlib.pyplot as plt\n","\n","# Load the dataset\n","df = pd.read_csv(\"flights_EDA.csv\")\n","\n","# Define features and target\n","categorical_cols = ['carrier', 'origin', 'dest', 'flight_status']\n","num_cols = ['dep_time', 'arr_time', 'air_time', 'distance']\n","\n","X = df[categorical_cols + num_cols]\n","y = (df['total_delay'] > 20).astype(int)\n","\n","# Split the data into training, validation, and test sets\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=1)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n","\n","# Preprocessing pipeline\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), num_cols),\n","        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n","    ]\n",")\n","\n","# Preprocess the data\n","X_train_preprocessed = preprocessor.fit_transform(X_train)\n","X_val_preprocessed = preprocessor.transform(X_val)\n","X_test_preprocessed = preprocessor.transform(X_test)\n","\n","# Create the FFNN model\n","model = Sequential([\n","    Dense(64, activation='relu', input_shape=(X_train_preprocessed.shape[1],)),\n","    Dropout(0.2),\n","    Dense(32, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Early stopping\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',\n","    patience=3,\n","    restore_best_weights=True\n",")\n","\n","# Train the FFNN\n","FFN = model.fit(\n","    X_train_preprocessed, y_train,\n","    validation_data=(X_val_preprocessed, y_val),\n","    epochs=20,\n","    batch_size=64,\n","    callbacks=[early_stopping],\n","    verbose=1\n",")\n","\n","# Evaluate on the validation set\n","y_val_pred = (model.predict(X_val_preprocessed) > 0.5).astype(int)\n","y_val_prob = model.predict(X_val_preprocessed)  # Predicted probabilities for ROC-AUC\n","\n","print(\"Validation Set Metrics:\")\n","print(f\"Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n","print(f\"Classification Report:\\n{classification_report(y_val, y_val_pred)}\")\n","print(f\"Confusion Matrix:\\n{confusion_matrix(y_val, y_val_pred)}\")\n","print(f\"ROC-AUC Score: {roc_auc_score(y_val, y_val_prob):.4f}\")\n","\n","# Plot ROC curve for validation set\n","fpr, tpr, thresholds = roc_curve(y_val, y_val_prob)\n","plt.figure()\n","plt.plot(fpr, tpr, label=f\"Validation AUC-ROC = {roc_auc_score(y_val, y_val_prob):.4f}\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve (Validation Set)\")\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","# Evaluate on the test set\n","y_test_pred = (model.predict(X_test_preprocessed) > 0.5).astype(int)\n","y_test_prob = model.predict(X_test_preprocessed)  # Predicted probabilities for ROC-AUC\n","\n","print(\"\\nTest Set Metrics:\")\n","print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n","print(f\"Classification Report:\\n{classification_report(y_test, y_test_pred)}\")\n","print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_test_pred)}\")\n","print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_test_prob):.4f}\")\n","\n","# Plot ROC curve for test set\n","fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n","plt.figure()\n","plt.plot(fpr, tpr, label=f\"Test AUC-ROC = {roc_auc_score(y_test, y_test_prob):.4f}\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC Curve (Test Set)\")\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"metadata":{"id":"Ppmk3jF-CNMe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------------------------------------------------------------------\n","# Results\n","\n","The Feedforward Neural Network (FFNN) demonstrated exceptional performance, achieving 99.89% accuracy on the validation set and 99.90% accuracy on the test set, with a perfect ROC-AUC score of 1.0000. The model made minimal errors, with only 19 false positives and 31 false negatives on the test set, indicating near-flawless classification of flight delays greater than 20 minutes. This outstanding performance makes the FFNN highly reliable for real-world applications, such as predicting delays for passenger notifications or operational planning.\n","\n","# Disclaimer:\n","We believe the data may be overfitting or the classification might be too easy considering the attributes it uses to classify properly."],"metadata":{"id":"qoWAtzeYCX-U"}},{"cell_type":"markdown","source":["--------------------------------------------------------------------------------\n","# Conclusion and Next Steps\n","\n","After evaluating the Random Forest Classifier (RFC), Support Vector Machine (SVM), and Feedforward Neural Network (FFNN) for classifying flight delays greater than 20 minutes, all three models demonstrated exceptional performance. The FFNN achieved the highest accuracy (99.90%) and a perfect ROC-AUC score (1.0000), followed closely by the SVM (99.99% accuracy and ROC-AUC of 1.0000) and the RFC (98.13% accuracy and ROC-AUC of 0.9965). While the FFNN and SVM outperformed the RFC in this classification task, the RFC still delivered strong results and may offer better interpretability for feature importance analysis.\n","\n","Before proceeding with feature engineering, we will compare these models in a regression task to predict the absolute continuous `total_delay`. This will provide a deeper understanding of how each model performs when predicting the exact delay time, rather than just classifying delays. Regression will help us identify which model best captures the nuances of delay patterns, which is critical for recommending optimal flight times.\n","\n","Once we complete the regression comparison, we can select the best-performing model and refine it further through feature engineering, hyperparameter tuning, and additional analysis to ensure it meets the specific needs of our use case. This step-by-step approach ensures a robust and well-informed solution for predicting and mitigating flight delays.\n","\n","\n","\n"],"metadata":{"id":"rEEs7cqfCZCR"}},{"cell_type":"markdown","source":["#Regression Models\n","The objective is to train and evaluate three machine learning models which are Random Forest Regressor, Support Vector Machine Regressor(SVM), and a Feed Forward Neural Network to predict flight delays based on the total_delay target variable. Specifically, we will:\n","\n","Train and evaluate each model using the preprocessed dataset from the EDA phase.\n","\n","Compare the performance of the models to determine which one is the most effective at predicting delays.\n","\n","Analyze the strengths and weaknesses of each model to understand why certain models perform better.\n","\n","Explore potential improvements and discuss refinements"],"metadata":{"id":"NhhA5tUSGxrH"}},{"cell_type":"markdown","source":["#1. Training the Random Forest Regessor Model"],"metadata":{"id":"0vr2y9eQHCbS"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_poisson_deviance\n","from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score,recall_score\n","\n","\n","df=pd.read_csv('flights_EDA.csv')\n","\n","\n","X= df.drop(columns=['total_delay', 'id', 'time_hour', 'name', 'dep_delay', 'arr_delay'])\n","\n","\n","#list all the categorical columns and numerical\n","categorical_cols =['carrier', 'origin', 'dest', 'flight_status', 'flight', 'tailnum']\n","num_cols =['dep_time', 'arr_time', 'air_time', 'distance']\n","# Define the target variable for regression\n","y = df['total_delay']\n","\n","# Split the data (same as before)\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=1)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n","\n","# Create the preprocessing pipeline (same as before)\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), num_cols),  # Scale numerical features\n","        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)  # One-hot encode categorical features\n","])\n","\n","# Create the Random Forest Regression pipeline\n","regression_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('regressor', RandomForestRegressor(n_estimators=10, n_jobs=-1, random_state=1))  # Use RandomForestRegressor  might use this attribute for 1minute runtime but the results are skewed slightly = max_depth=10\n","])\n","\n","# Train the regression model\n","regression_pipeline.fit(X_train, y_train)\n","print('Regression model training complete')\n","\n","# Predict on the validation set\n","y_val_pred = regression_pipeline.predict(X_val)\n","\n","# Evaluate on the validation set\n","print(f\"Validation Mean Squared Error (MSE): {mean_squared_error(y_val, y_val_pred):.4f}\")\n","print(f\"Validation Mean Absolute Error (MAE): {mean_absolute_error(y_val, y_val_pred):.4f}\")\n","print(f\"Validation R-squared: {r2_score(y_val, y_val_pred):.4f}\")\n","try:\n","    print(f\"Validation Poisson Deviance: {mean_poisson_deviance(y_val, y_val_pred):.4f}\")\n","except ValueError as e:\n","    print(f\"Validation Poisson Deviance could not be calculated: {e}\")\n","\n","# Predict on the test set\n","y_test_pred = regression_pipeline.predict(X_test)\n","\n","# Evaluate on the test set\n","print(f\"Test Mean Squared Error (MSE): {mean_squared_error(y_test, y_test_pred):.4f}\")\n","print(f\"Test Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_test_pred):.4f}\")\n","print(f\"Test R-squared: {r2_score(y_test, y_test_pred):.4f}\")\n","try:\n","    print(f\"Test Poisson Deviance: {mean_poisson_deviance(y_test, y_test_pred):.4f}\")\n","except ValueError as e:\n","    print(f\"Test Poisson Deviance could not be calculated: {e}\")\n","\n","from sklearn.metrics import mean_absolute_percentage_error\n","print(f\"Test MAPE: {mean_absolute_percentage_error(y_test, y_test_pred):.4f}\")\n","\n","import numpy as np\n","def smape(y_true, y_pred):\n","    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n","print(f\"Test SMAPE: {smape(y_test, y_test_pred):.4f}\")\n","\n","from sklearn.metrics import mean_absolute_error\n","def mase(y_true, y_pred, y_train):\n","    mae = mean_absolute_error(y_true, y_pred)\n","    mae_naive = mean_absolute_error(y_train[1:], y_train[:-1])  # Naive forecast\n","    return mae / mae_naive\n","print(f\"Test MASE: {mase(y_test, y_test_pred, y_train):.4f}\")"],"metadata":{"id":"ZJiICXGbG3mz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Results\n","The Random Forest Regressor demonstrated strong performance in predicting flight delays, achieving a validation R² of 1.0000 and a test R² of 0.9996, indicating an excellent fit to the data. The model's validation MSE (0.3419) and MAE (0.0790) were low, suggesting high accuracy on the validation set. However, the test MSE (2.7128) and MAE (0.0906) were slightly higher, indicating some overfitting to the training data. The SMAPE (13.88%) and MASE (0.0014) further confirm the model's strong predictive capability. While the Poisson Deviance could not be calculated due to negative predictions, the overall results suggest that the Random Forest Regressor is highly effective for this regression task."],"metadata":{"id":"LIyW_82yHKxo"}},{"cell_type":"markdown","source":["We will now perform a 5-fold cross-validation on the regression pipeline to evaluate its performance using the Mean Squared Error (MSE) metric. By averaging the MSE scores across all folds, it provides a robust estimate of the model's generalization ability."],"metadata":{"id":"89eWHah3HPZN"}},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score\n","scores = cross_val_score(regression_pipeline, X, y, scoring='neg_mean_squared_error', cv=5)\n","print(f\"Cross-Validation MSE: {-scores.mean():.4f}\")"],"metadata":{"id":"GNA1-HtTHQgS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["the cross validation score suggests that the Random Forest Regressor performs well in generalizing to unseen data, because it is close to zero. We will now display the feature importances from the Random Forest Regressor model."],"metadata":{"id":"1Al4s-lcHTJH"}},{"cell_type":"code","source":["importances = regression_pipeline.named_steps['regressor'].feature_importances_\n","feature_names = num_cols + list(regression_pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_cols))\n","print(pd.Series(importances, index=feature_names).sort_values(ascending=False))"],"metadata":{"id":"b9z-WZZ4HWVu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can gather from above that dep_delay is the most significant feature, contributing 82.2% to the model's predictions, followed by arr_delay at 17.79%. The remaining features, such as air_time, arr_time, and dep_time, have negligible importance, with many categorical features (e.g., specific flights or tail numbers) contributing 0%. This suggests that departure and arrival delays are the primary drivers of flight delays, while other features have minimal impact."],"metadata":{"id":"938aVRYyHaJ-"}},{"cell_type":"code","source":["'''\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","param_grid = {\n","    'regressor__n_estimators': [10, 50, 100],\n","    'regressor__max_depth': [10, 20, None],\n","    'regressor__min_samples_split': [2, 5, 10],\n","    'regressor__min_samples_leaf': [1, 2, 4]\n","}\n","\n","random_search = RandomizedSearchCV(regression_pipeline, param_grid, n_iter=10, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, random_state=1)\n","random_search.fit(X, y)\n","print(f\"Best Parameters: {random_search.best_params_}\")\n","print(f\"Best Cross-Validation MSE: {-random_search.best_score_:.4f}\")\n","''' EDITTING THE MODEL TO IMPROVE PERFORMANCE / FEATURE SELECTION"],"metadata":{"id":"At9KPQ4dHbCi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#2. Training SVR Model\n","We will now implement a Linear Support Vector Regressor (LinearSVR) for predicting flight delays. It uses a preprocessing pipeline to scale numerical features and one-hot encode categorical features. A RandomizedSearchCV is employed for hyperparameter tuning, focusing on the regularization parameter C with fewer iterations and folds to reduce computational cost. After fitting the model, the best parameters and cross-validation MSE are printed. The model is then evaluated on the test set using metrics like MSE, MAE, and R², providing insights into its predictive performance. This streamlined approach balances efficiency and model optimization, making it suitable for large datasets."],"metadata":{"id":"fBzwUNCqHeqP"}},{"cell_type":"code","source":["from sklearn.svm import LinearSVR\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","# Create the preprocessing pipeline\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), num_cols),  # Scale numerical features\n","        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)  # One-hot encode categorical features\n","    ]\n",")\n","\n","# Create the SVR pipeline with LinearSVR\n","svr_pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),  # Preprocessing\n","    ('regressor', LinearSVR(random_state=1))  # LinearSVR\n","])\n","\n","# Define the hyperparameter grid for LinearSVR\n","svr_param_grid = {\n","    'regressor__C': [0.1, 1, 10],  # Fewer values for C\n","}\n","\n","# Perform randomized search for hyperparameter tuning\n","random_search_svr = RandomizedSearchCV(\n","    svr_pipeline,\n","    svr_param_grid,\n","    n_iter=5,  # Fewer iterations\n","    scoring='neg_mean_squared_error',\n","    cv=2,  # Fewer folds\n","    n_jobs=-1,  # Use all CPU cores\n","    random_state=1\n",")\n","\n","# Fit the model\n","random_search_svr.fit(X, y)\n","\n","# Print the best parameters and MSE\n","print(f\"Best Parameters: {random_search_svr.best_params_}\")\n","print(f\"Best Cross-Validation MSE: {-random_search_svr.best_score_:.4f}\")\n","\n","# Evaluate on the test set\n","y_test_pred_svr = random_search_svr.predict(X_test)\n","print(f\"Test Mean Squared Error (MSE): {mean_squared_error(y_test, y_test_pred_svr):.4f}\")\n","print(f\"Test Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_test_pred_svr):.4f}\")\n","print(f\"Test R-squared: {r2_score(y_test, y_test_pred_svr):.4f}\")"],"metadata":{"id":"V0gQ7QCtHpdt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------------------------------------------------------------------\n","# Results\n","\n","The output indicates that the LinearSVR model achieved perfect performance on both the validation and test sets. The best hyperparameter found was C=10, and the cross-validation MSE and test MSE were both 0.0000, with an R² of 1.0000. This suggests the model fits the data perfectly, which could indicate overfitting or issues with the dataset, such as data leakage or insufficient variability. The warning about the parameter space being smaller than n_iter suggests that a GridSearchCV might be more appropriate for exhaustive tuning."],"metadata":{"id":"6PKVUbvuHsqJ"}},{"cell_type":"markdown","source":["# 2nd Support Vector Regressor (SVR)\n","\n","Here we implement a Linear Support Vector Regressor (LinearSVR) for predicting flight delays and the data is split into training, validation, and test sets, and preprocessing is applied separately. A RandomizedSearchCV is used for hyperparameter tuning, exploring values for C (regularization) and epsilon (insensitivity margin) to optimize the model."],"metadata":{"id":"5iiVa52IHySk"}},{"cell_type":"code","source":["from sklearn.svm import LinearSVR\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","import matplotlib.pyplot as plt\n","\n","# Check the distribution of the target variable\n","plt.hist(y, bins=50)\n","plt.title('Distribution of Target Variable (total_delay)')\n","plt.xlabel('Total Delay')\n","plt.ylabel('Frequency')\n","plt.show()\n","\n","# Split the data into training, validation, and test sets\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=1)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n","\n","# Fit the preprocessing pipeline on the training data\n","preprocessor.fit(X_train)\n","\n","# Transform the training, validation, and test data\n","X_train_preprocessed = preprocessor.transform(X_train)\n","X_val_preprocessed = preprocessor.transform(X_val)\n","X_test_preprocessed = preprocessor.transform(X_test)\n","\n","# Create the SVR pipeline with LinearSVR\n","svr_pipeline = Pipeline(steps=[\n","    ('regressor', LinearSVR(random_state=1))  # No preprocessor in the pipeline\n","])\n","\n","# Define the hyperparameter grid for LinearSVR\n","svr_param_grid = {\n","    'regressor__C': [0.01, 0.1, 1, 10, 100],  # More values for C\n","    'regressor__epsilon': [0.01, 0.1, 1],  # Add epsilon for LinearSVR\n","}\n","\n","# Perform randomized search for hyperparameter tuning\n","random_search_svr = RandomizedSearchCV(\n","    svr_pipeline,\n","    svr_param_grid,\n","    n_iter=10,  # More iterations\n","    scoring='neg_mean_squared_error',\n","    cv=2,  # Fewer folds\n","    n_jobs=-1,  # Use all CPU cores\n","    random_state=1\n",")\n","\n","# Fit the model on the preprocessed training data\n","random_search_svr.fit(X_train_preprocessed, y_train)\n","\n","# Print the best parameters and MSE\n","print(f\"Best Parameters: {random_search_svr.best_params_}\")\n","print(f\"Best Cross-Validation MSE: {-random_search_svr.best_score_:.4f}\")\n","\n","# Evaluate on the test set\n","y_test_pred_svr = random_search_svr.predict(X_test_preprocessed)\n","print(f\"Test Mean Squared Error (MSE): {mean_squared_error(y_test, y_test_pred_svr):.4f}\")\n","print(f\"Test Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_test_pred_svr):.4f}\")\n","print(f\"Test R-squared: {r2_score(y_test, y_test_pred_svr):.4f}\")"],"metadata":{"id":"YGsaNtnZICC5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------------------------------------------------------------------\n","# Results\n","\n","The LinearSVR model achieved perfect performance on the validation and test sets, with a cross-validation MSE of 0.0000 and a test MSE of 0.0000, along with an R² of 1.0000. The best hyperparameters were found to be epsilon=0.01 and C=0.1. While the MAE of 0.0038 indicates minimal error, the perfect MSE and R² scores suggest the model fits the data exceptionally well. However, such results may indicate overfitting"],"metadata":{"id":"VIT_lldZIFPW"}},{"cell_type":"markdown","source":["# 3. Training The FeedForward Neural Network Model\n","About 2 minute runtime.\n","\n"],"metadata":{"id":"-Svg6TEBIJ5_"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Load the dataset\n","df = pd.read_csv('flights_EDA.csv')\n","\n","# Define the target variable\n","y = df['total_delay']\n","\n","# Define the feature matrix X\n","categorical_cols = ['carrier', 'origin', 'dest', 'flight_status']  # Categorical features\n","num_cols = ['dep_time', 'arr_time', 'air_time', 'distance']  # Numerical features\n","X = df[categorical_cols + num_cols]  # Combine categorical and numerical features\n","\n","# Split the data\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=1)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n","\n","# Create the preprocessing pipeline\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', StandardScaler(), num_cols),  # Scale numerical features\n","        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)  # One-hot encode categorical features\n","    ]\n",")\n","\n","# Preprocess the data\n","X_train_preprocessed = preprocessor.fit_transform(X_train)\n","X_val_preprocessed = preprocessor.transform(X_val)\n","X_test_preprocessed = preprocessor.transform(X_test)\n","\n","# Define the FNN model\n","model = Sequential([\n","    Dense(64, activation='relu', input_shape=(X_train_preprocessed.shape[1],)),  # Smaller input layer\n","    Dropout(0.2),  # Dropout for regularization\n","    Dense(32, activation='relu'),  # Smaller hidden layer\n","    Dense(1)  # Output layer (regression)\n","])\n","\n","# Compile the model\n","model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n","\n","# Early stopping\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',  # Monitor validation loss\n","    patience=3,  # Stop after 3 epochs without improvement\n","    restore_best_weights=True  # Restore the best model weights\n",")\n","\n","# Train the model\n","history = model.fit(\n","    X_train_preprocessed, y_train,\n","    validation_data=(X_val_preprocessed, y_val),\n","    epochs=20,  # Fewer epochs\n","    batch_size=64,  # Larger batch size\n","    callbacks=[early_stopping],  # Add early stopping\n","    verbose=1\n",")\n","\n","# Evaluate the model on the test set\n","test_loss, test_mae = model.evaluate(X_test_preprocessed, y_test, verbose=0)\n","print(f\"Test Mean Squared Error (MSE): {test_loss:.4f}\")\n","print(f\"Test Mean Absolute Error (MAE): {test_mae:.4f}\")\n","\n","# Make predictions\n","y_test_pred = model.predict(X_test_preprocessed).flatten()\n","\n","# Calculate R-squared\n","from sklearn.metrics import r2_score\n","print(f\"Test R-squared: {r2_score(y_test, y_test_pred):.4f}\")"],"metadata":{"id":"6rho_XZbIGu5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Results\n","The Feedforward Neural Network (FFNN) achieved excellent performance, with a Test MSE of 0.7505, Test MAE of 0.5782, and a near-perfect R² of 0.9999, indicating an almost perfect fit to the data. The model's training process showed consistent improvement, with validation loss decreasing over epochs. Early stopping prevented overfitting, and the model generalized well to the test set."],"metadata":{"id":"ypIVtu8-IM0f"}},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error, explained_variance_score\n","from matplotlib import pyplot as plt\n","\n","# Make predictions\n","y_test_pred = model.predict(X_test_preprocessed).flatten()\n","\n","# Calculate additional metrics\n","test_rmse = np.sqrt(test_loss)  # RMSE\n","test_mape = mean_absolute_percentage_error(y_test, y_test_pred)  # MAPE\n","test_explained_variance = explained_variance_score(y_test, y_test_pred)  # Explained Variance\n","\n","# Print additional metrics\n","print(f\"Test Root Mean Squared Error (RMSE): {test_rmse:.4f}\")\n","print(f\"Test Mean Absolute Percentage Error (MAPE): {test_mape:.4f}\")\n","print(f\"Test Explained Variance: {test_explained_variance:.4f}\")\n","\n","# Residual Analysis\n","residuals = y_test - y_test_pred\n","plt.figure(figsize=(10, 6))\n","plt.scatter(y_test_pred, residuals, alpha=0.5)\n","plt.axhline(y=0, color='r', linestyle='--')\n","plt.title('Residual Plot')\n","plt.xlabel('Predicted Values')\n","plt.ylabel('Residuals')\n","plt.show()"],"metadata":{"id":"4c-RANqEIPtJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Weather Scraping"],"metadata":{"id":"8Gw8P7ffLFJb"}},{"cell_type":"markdown","source":["We attempted to retrieve historical weather data for specific flight times and locations using the OpenWeatherMap API. The retrieved weather data is then cleaned and structured to match our historical flight data. Finally, the flight data and weather information was merged based on matching the timestamps and locations of the flights, creating a comprehensive data set for analysis."],"metadata":{"id":"qVktFSEACq-J"}},{"cell_type":"code","source":["import pandas as pd\n","import requests\n","\n","\n","df = pd.read_csv(\"flights_EDA_for_feature_engineering.csv\")"],"metadata":{"id":"3v2UgyRvLfOd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datetime import datetime\n","import time\n","import pytz\n","\n","\n","\n","origin_airport_latitude = {\n","    'JFK': 40.6446,\n","    'LGA': 40.7766,\n","    'EWR': 40.6885\n","}\n","\n","origin_airport_longitude = {\n","    'JFK': -73.7797,\n","    'LGA': -73.8742,\n","    'EWR': -74.1769\n","}\n","\n","dest_airport_latitude = {\n","    'IAH': 29.9931,\n","    'MIA': 25.7923,\n","    'BQN': 18.4954,\n","    'ATL': 33.6324,\n","    'ORD': 41.9803,\n","    'FLL': 26.0720,\n","    'IAD': 38.9522,\n","    'MCO': 28.4230,\n","    'PBI': 26.6857,\n","    'TPA': 27.9769,\n","    'LAX': 33.9422,\n","    'SFO': 37.6191,\n","    'DFW': 32.8990,\n","    'BOS': 42.3656,\n","    'LAS': 36.0831,\n","    'MSP': 44.8851,\n","    'DTW': 42.2132,\n","    'RSW': 26.5319,\n","    'SJU': 18.4395,\n","    'PHX': 33.4352,\n","    'BWI': 39.1776,\n","    'CLT': 35.2163,\n","    'BUF': 42.9394,\n","    'DEN': 39.8563,\n","    'SNA': 33.6747,\n","    'MSY': 29.9940,\n","    'SLC': 40.7903,\n","    'XNA': 36.2806,\n","    'MKE': 42.9439,\n","    'SEA': 47.4484,\n","    'ROC': 43.1164,\n","    'SYR': 43.1112,\n","    'SRQ': 27.3951,\n","    'RDU': 35.8798,\n","    'CMH': 39.9999,\n","    'JAX': 30.4943,\n","    'CHS': 32.8917,\n","    'MEM': 35.0443,\n","    'PIT': 40.4929,\n","    'SAN': 32.7332,\n","    'DCA': 38.8512,\n","    'CLE': 41.4058,\n","    'STL': 38.7499,\n","    'MYR': 33.6822,\n","    'JAC': 43.6088,\n","    'MDW': 41.7868,\n","    'HNL': 21.3187,\n","    'BNA': 36.1249,\n","    'AUS': 30.1941,\n","    'BTV': 44.4728,\n","    'PHL': 39.8730,\n","    'STT': 18.3367,\n","    'EGE': 39.6423,\n","    'AVL': 35.4349,\n","    'PWM': 43.6460,\n","    'IND': 39.7223,\n","    'SAV': 32.1294,\n","    'CAK': 40.9154,\n","    'HOU': 29.6459,\n","    'LGB': 33.8161,\n","    'DAY': 39.9025,\n","    'ALB': 42.7480,\n","    'BDL': 41.9389,\n","    'MHT': 42.9297,\n","    'MSN': 43.1389,\n","    'GSO': 36.1029,\n","    'CVG': 39.0514,\n","    'BUR': 34.1983,\n","    'RIC': 37.5106,\n","    'GSP': 34.8959,\n","    'GRR': 42.8826,\n","    'MCI': 39.3014,\n","\n","    'ORF': 36.8935,\n","    'SAT': 29.5331,\n","    'SDF': 38.1707,\n","    'PDX': 45.5853,\n","    'SJC': 37.3635,\n","    'OMA': 41.3015,\n","    'CRW': 38.3705,\n","    'OAK': 37.7212,\n","    'SMF': 38.6944,\n","    'TUL': 36.2012,\n","    'TYS': 35.8065,\n","    'PVD': 41.7235,\n","    'DSM': 41.5341,\n","    'PSE': 18.0106,\n","    'BHM': 33.5625,\n","    'OKC': 35.3888,\n","    'CAE': 33.9419,\n","    'HDN': 40.4847,\n","    'BZN': 45.7784,\n","    'MTJ': 38.5002,\n","    'EYW': 24.5537,\n","    'PSP': 33.8303,\n","    'ACK': 41.2570,\n","    'BGR': 44.8080,\n","    'AQB': 35.0405,\n","    'ILM': 34.2670,\n","    'MVY': 41.3893,\n","    'SBN': 41.7077,\n","    'LEX': 38.0374,\n","    'CHO': 38.1390,\n","    'TVC': 44.7414,\n","    'ANC': 61.1769\n","}\n","\n","dest_airport_longitude = {\n","    'IAH': -95.3416,\n","    'MIA': -80.2823,\n","    'BQN': -67.1356,\n","    'ATL': -84.4333,\n","    'ORD': -87.9090,\n","    'FLL': -80.1501,\n","    'MCO': -81.3115,\n","    'IAD': -77.4579,\n","    'PBI': -80.0928,\n","    'TPA': -82.5303,\n","    'LAX': -118.4036,\n","    'SFO': -122.3816,\n","    'DFW': -97.0336,\n","    'BOS': -71.0096,\n","    'LAS': -115.1482,\n","    'MSP': -93.2144,\n","    'DTW': -83.3525,\n","    'RSW': -81.7596,\n","    'SJU': -65.9992,\n","    'PHX': -112.0101,\n","    'BWI': -76.6684,\n","    'CLT': -80.9539,\n","    'BUF': -78.7335,\n","    'DEN': -104.6764,\n","    'SNA': -117.8692,\n","    'MSY': -90.2597,\n","    'SLC': -111.9771,\n","    'XNA': -94.3046,\n","    'MKE': -87.9008,\n","    'SEA': -122.3086,\n","    'ROC': -77.6748,\n","    'SYR': -76.1143,\n","    'SRQ': -82.5538,\n","    'RDU': -78.7856,\n","    'CMH': -82.8872,\n","    'JAX': -81.6871,\n","    'CHS': -80.0395,\n","    'MEM': -89.9766,\n","    'PIT': -80.2373,\n","    'SAN': -117.1897,\n","    'DCA': -77.0402,\n","    'CLE': -81.8539,\n","    'STL': -90.3748,\n","    'MYR': -78.9279,\n","    'JAC': -110.7376,\n","    'MDW': -87.7522,\n","    'HNL': -157.9254,\n","    'BNA': -86.6762,\n","    'AUS': -97.6711,\n","    'BTV': -73.1515,\n","    'PHL': -75.2437,\n","    'STT': -64.9727,\n","    'EGE': -106.9170,\n","    'AVL': -82.5379,\n","    'PWN': -70.3064,\n","    'IND': -86.3020,\n","    'SAV': -81.2019,\n","    'CAK': -81.4416,\n","    'HOU': -95.2769,\n","    'LGB': -118.1513,\n","    'DAY': -84.2218,\n","    'ALB': -73.8026,\n","    'BDL': -72.6860,\n","    'MHT': -71.4352,\n","    'MSN': -89.3369,\n","    'GSO': -79.9335,\n","    'CVG': -84.6671,\n","    'BUR': -118.3574,\n","    'RIC': -77.3267,\n","    'GSP': -82.2172,\n","    'GRR': -85.5240,\n","    'MCI': -94.7105,\n","    'PWM': -70.3064,\n","    'ORF': -76.1994,\n","    'SAT': -98.4705,\n","    'SDF': -85.7308,\n","    'PDX': -122.5917,\n","    'SJC': -121.9286,\n","    'OMA': -95.8945,\n","    'CRW': -81.5964,\n","    'OAK': -122.2236,\n","    'SMF': -121.5888,\n","    'TUL': -95.8850,\n","    'TYS': -83.9982,\n","    'PVD': -71.4270,\n","    'DSM': -93.6588,\n","    'PSE': -66.5632,\n","    'BHM': -86.7542,\n","    'OKC': -97.6001,\n","    'CAE': -81.1220,\n","    'HDN': -107.2197,\n","    'BZN': -111.1612,\n","    'MTJ': -107.8992,\n","    'EYW': -81.7550,\n","    'PSP': -116.5070,\n","    'ACK': -70.0638,\n","    'BGR': -68.8166,\n","    'ABQ': -106.6098,\n","    'ILM': -77.9105,\n","    'MVY': -70.6122,\n","    'SBN': -86.3158,\n","    'LEX': -84.6034,\n","    'CHO': -78.4518,\n","    'TVC': -85.5793,\n","    'ANC': -149.9906\n","}\n","edst_airports = ['EWR', 'LGA', 'JFK', 'MIA', 'ATL', 'FLL', 'IAD', 'MCO', 'PBI', 'TPA', 'BOS', 'DTW', 'RSW', 'BWI', 'CLT', 'BUF', 'ROC', 'SYR', 'SRQ', 'RDU', 'CMH', 'JAX', 'CHS', 'PIT', 'DCA', 'CLE', 'MYR', 'BTV',\n","'PHL', 'AVL', 'PWM', 'IND', 'SAV', 'CAK', 'DAY', 'ALB', 'BDL', 'MHT', 'GSO', 'CVG', 'RIC', 'GSP', 'GRR', 'ORF', 'SDF', 'CRW', 'TYS', 'PVD', 'CAE', 'EYW', 'ACK', 'BGR', 'ILM',\n","'MVY', 'LEX', 'CHO', 'TVC']\n","\n","pst_airports = ['LAX', 'SFO', 'LAS', 'SNA', 'SEA', 'SAN', 'LGB', 'BUR', 'PDX', 'SJC', 'OAK', 'SMF', 'PSP']\n","\n","cdst_airports = ['IAH', 'ORD', 'DFW', 'MSP', 'MSY', 'XNA', 'MKE', 'MEM', 'STL', 'MDW', 'BNA', 'AUS', 'HOU', 'MSN', 'MCI', 'SAT', 'OMA', 'TUL', 'DSM', 'BHM', 'OKC']\n","\n","ast_airports = ['BQN', 'SJU', 'STT', 'PSE']\n","\n","mst_airports = ['PHX']\n","\n","mdt_airports = ['DEN', 'SLC', 'JAC', 'EGE', 'HDN', 'BZN', 'MTJ', 'ABQ']\n","\n","hast_airports = ['HNL']\n","\n","indianapolis_airports = ['SBN']\n","\n","alaskadst_airports = ['ANC']\n","\n","sched_dep_temperatures_dict = {}\n","sched_dep_humidity_dict = {}\n","sched_dep_pressure_dict = {}\n","sched_dep_dew_point_dict = {}\n","sched_dep_clouds_dict = {}\n","sched_dep_visibility_dict = {}\n","sched_dep_wind_speed_dict = {}\n","sched_dep_wind_deg_dict = {}\n","sched_dep_weather_main_dict = {}\n","sched_dep_weather_main_desc_dict = {}\n","\n","arr_dep_temperatures_dict = {}\n","arr_dep_humidity_dict = {}\n","arr_dep_pressure_dict = {}\n","arr_dep_dew_point_dict = {}\n","arr_dep_clouds_dict = {}\n","arr_dep_visibility_dict = {}\n","arr_dep_wind_speed_dict = {}\n","arr_dep_wind_deg_dict = {}\n","arr_dep_weather_main_dict = {}\n","arr_dep_weather_main_desc_dict = {}\n","\n","def weather_data(api, flight_id, location, lat, lon, unix_date):\n","    root_url = f'https://api.openweathermap.org/data/3.0/onecall/timemachine?lat={lat}&lon={lon}&dt={unix_date}&units=metric&appid={api}'\n","    response = requests.get(root_url)\n","\n","    try:\n","        response = requests.get(root_url)\n","        response.raise_for_status()\n","        data = response.json()\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Error getting the data {e}\")\n","        time.sleep(0.5)\n","        return None\n","    if location == 'dep':\n","        sched_dep_temperature = data['data'][0].get('temp', None)\n","        sched_dep_pressure = data['data'][0].get('pressure', None)\n","        sched_dep_humidity = data['data'][0].get('humidity', None)\n","        sched_dep_dew_point = data['data'][0].get('dew_point', None)\n","        sched_dep_clouds = data['data'][0].get('clouds', None)\n","        sched_dep_wind_speed = data['data'][0].get('wind_speed', None)\n","        sched_dep_wind_deg = data['data'][0].get('wind_deg', None)\n","        sched_dep_visibility = data['data'][0].get('visibility', None)\n","        sched_dep_weather_main = data['data'][0].get('weather', [{}])[0].get('main', None)\n","        sched_dep_weather_main_desc = data['data'][0].get('weather', [{}])[0].get('description', None)\n","\n","        sched_dep_temperatures_dict[flight_id] = sched_dep_temperature\n","        sched_dep_pressure_dict[flight_id] = sched_dep_pressure\n","        sched_dep_humidity_dict[flight_id] = sched_dep_humidity\n","        sched_dep_dew_point_dict[flight_id] = sched_dep_dew_point\n","        sched_dep_clouds_dict[flight_id] = sched_dep_clouds\n","        sched_dep_visibility_dict[flight_id] = sched_dep_visibility\n","        sched_dep_wind_speed_dict[flight_id] = sched_dep_wind_speed\n","        sched_dep_wind_deg_dict[flight_id] = sched_dep_wind_deg\n","        sched_dep_weather_main_dict[flight_id] = sched_dep_weather_main\n","        sched_dep_weather_main_desc_dict[flight_id] = sched_dep_weather_main_desc\n","    elif location == 'arr':\n","        arr_dep_temperature = data['data'][0].get('temp', None)\n","        arr_dep_pressure = data['data'][0].get('pressure', None)\n","        arr_dep_humidity = data['data'][0].get('humidity', None)\n","        arr_dep_dew_point = data['data'][0].get('dew_point', None)\n","        arr_dep_clouds = data['data'][0].get('clouds', None)\n","        arr_dep_wind_speed = data['data'][0].get('wind_speed', None)\n","        arr_dep_wind_deg = data['data'][0].get('wind_deg', None)\n","        arr_dep_visibility = data['data'][0].get('visibility', None)\n","        arr_dep_weather_main = data['data'][0].get('weather', [{}])[0].get('main', None)\n","        arr_dep_weather_main_desc = data['data'][0].get('weather', [{}])[0].get('description', None)\n","\n","        arr_dep_temperatures_dict[flight_id] = arr_dep_temperature\n","        arr_dep_pressure_dict[flight_id] = arr_dep_pressure\n","        arr_dep_humidity_dict[flight_id] = arr_dep_humidity\n","        arr_dep_dew_point_dict[flight_id] = arr_dep_dew_point\n","        arr_dep_clouds_dict[flight_id] = arr_dep_clouds\n","        arr_dep_visibility_dict[flight_id] = arr_dep_visibility\n","        arr_dep_wind_speed_dict[flight_id] = arr_dep_wind_speed\n","        arr_dep_wind_deg_dict[flight_id] = arr_dep_wind_deg\n","        arr_dep_weather_main_dict[flight_id] = arr_dep_weather_main\n","        arr_dep_weather_main_desc_dict[flight_id] = arr_dep_weather_main_desc\n","\n","\n","\n","def convert_time_to_unix(airport, dep_time, year, month, day):\n","    dep_time = datetime.strptime(str(dep_time), '%H%M')\n","\n","    if airport in edst_airports:\n","        timezone = pytz.timezone('America/New_York')\n","    elif airport in pst_airports:\n","        timezone = pytz.timezone('America/Los_Angeles')\n","    elif airport in cdst_airports:\n","        timezone = pytz.timezone('America/Chicago')\n","    elif airport in ast_airports:\n","        timezone = pytz.timezone(\"America/Puerto_Rico\")\n","    elif airport in mst_airports:\n","        timezone = pytz.timezone(\"America/Phoenix\")\n","    elif airport in mdt_airports:\n","        timezone = pytz.timezone(\"America/Denver\")\n","    elif airport in hast_airports:\n","        timezone = pytz.timezone(\"Pacific/Honolulu\")\n","    elif airport in indianapolis_airports:\n","        timezone = pytz.timezone(\"America/Indiana/Indianapolis\")\n","    elif airport in alaskadst_airports:\n","        timezone = pytz.timezone(\"America/Anchorage\")\n","\n","    origin_time = timezone.localize(dep_time.replace(year=year, month=month,day=day))\n","    utc_time = origin_time.astimezone(pytz.utc)\n","    unix_time = int(utc_time.timestamp())\n","    return unix_time\n","\n","for flight_id, origin_airport, destination_airport, sched_dep_time, sched_arr_time, year, month, day in zip(df['id'], df['origin'], df['dest'],\n","        df['sched_dep_time'], df['sched_arr_time'], df['year'], df['month'], df['day']):\n","\n","    orig_lat = origin_airport_latitude.get(origin_airport)\n","    orig_lon = origin_airport_longitude.get(origin_airport)\n","    # print(orig_lat)\n","    # print(orig_lon)\n","    dest_lat = dest_airport_latitude.get(destination_airport)\n","    dest_lon = dest_airport_longitude.get(destination_airport)\n","    # print(destination_airport)\n","    # print(dest_lat)\n","    # print(dest_lon)\n","\n","    unix_sched_dep_time = convert_time_to_unix(origin_airport, sched_dep_time, year, month, day)\n","    time.sleep(0.5)\n","    unix_sched_arr_time = convert_time_to_unix(destination_airport, sched_arr_time, year, month, day)\n","    time.sleep(0.5)\n","\n","\n","    # print(unix_sched_dep_time)\n","    # print(unix_sched_arr_time)\n","\n","    weather_data('', flight_id, 'dep', orig_lat, orig_lon, unix_sched_dep_time)\n","    time.sleep(1.5)\n","    weather_data('', flight_id, 'arr', dest_lat, dest_lon, unix_sched_arr_time)\n","    time.sleep(1.5)\n","\n","\n","# df[\"sched_dep_temp\"] = df[\"id\"].map(sched_dep_temperatures_dict)\n","# df[\"sched_dep_pressure\"] = df[\"id\"].map(sched_dep_pressure_dict)\n","# df[\"sched_dep_humidity\"] = df[\"id\"].map(sched_dep_humidity_dict)\n","# df[\"sched_dep_dew_point\"] = df[\"id\"].map(sched_dep_dew_point_dict)\n","# df[\"sched_dep_clouds\"] = df[\"id\"].map(sched_dep_clouds_dict)\n","# df[\"sched_dep_visibility\"] = df[\"id\"].map(sched_dep_visibility_dict)\n","# df[\"sched_dep_wind_deg\"] = df[\"id\"].map(sched_dep_wind_deg_dict)\n","# df[\"sched_dep_wind_speed\"] = df[\"id\"].map(sched_dep_wind_speed_dict)\n","# df[\"sched_dep_weather_main\"] = df[\"id\"].map(sched_dep_weather_main_dict)\n","# df[\"sched_dep_weather_main_desc\"] = df[\"id\"].map(sched_dep_weather_main_desc_dict)\n","\n","# df[\"sched_arr_temp\"] = df[\"id\"].map(arr_dep_temperatures_dict)\n","# df[\"sched_arr_pressure\"] = df[\"id\"].map(arr_dep_pressure_dict)\n","# df[\"sched_arr_humidity\"] = df[\"id\"].map(arr_dep_humidity_dict)\n","# df[\"sched_arr_dew_point\"] = df[\"id\"].map(arr_dep_dew_point_dict)\n","# df[\"sched_arr_clouds\"] = df[\"id\"].map(arr_dep_clouds_dict)\n","# df[\"sched_arr_visibility\"] = df[\"id\"].map(arr_dep_visibility_dict)\n","# df[\"sched_arr_wind_deg\"] = df[\"id\"].map(arr_dep_wind_deg_dict)\n","# df[\"sched_arr_wind_speed\"] = df[\"id\"].map(arr_dep_wind_speed_dict)\n","# df[\"sched_arr_weather_main\"] = df[\"id\"].map(arr_dep_weather_main_dict)\n","# df[\"sched_arr_weather_main_desc\"] = df[\"id\"].map(arr_dep_weather_main_desc_dict)\n","\n","# df.to_csv(\"flights_feature_engineering_third.csv\", index=False)\n","# print(\"\\nThe dataset has been saved as 'flights_feature_engineering_third.csv'.\")"],"metadata":{"id":"yGNKEbgeLN1r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[\"sched_dep_temp\"] = df[\"id\"].map(sched_dep_temperatures_dict)\n","df[\"sched_dep_pressure\"] = df[\"id\"].map(sched_dep_pressure_dict)\n","df[\"sched_dep_humidity\"] = df[\"id\"].map(sched_dep_humidity_dict)\n","df[\"sched_dep_dew_point\"] = df[\"id\"].map(sched_dep_dew_point_dict)\n","df[\"sched_dep_clouds\"] = df[\"id\"].map(sched_dep_clouds_dict)\n","df[\"sched_dep_visibility\"] = df[\"id\"].map(sched_dep_visibility_dict)\n","df[\"sched_dep_wind_deg\"] = df[\"id\"].map(sched_dep_wind_deg_dict)\n","df[\"sched_dep_wind_speed\"] = df[\"id\"].map(sched_dep_wind_speed_dict)\n","df[\"sched_dep_weather_main\"] = df[\"id\"].map(sched_dep_weather_main_dict)\n","df[\"sched_dep_weather_main_desc\"] = df[\"id\"].map(sched_dep_weather_main_desc_dict)\n","\n","df[\"sched_arr_temp\"] = df[\"id\"].map(arr_dep_temperatures_dict)\n","df[\"sched_arr_pressure\"] = df[\"id\"].map(arr_dep_pressure_dict)\n","df[\"sched_arr_humidity\"] = df[\"id\"].map(arr_dep_humidity_dict)\n","df[\"sched_arr_dew_point\"] = df[\"id\"].map(arr_dep_dew_point_dict)\n","df[\"sched_arr_clouds\"] = df[\"id\"].map(arr_dep_clouds_dict)\n","df[\"sched_arr_visibility\"] = df[\"id\"].map(arr_dep_visibility_dict)\n","df[\"sched_arr_wind_deg\"] = df[\"id\"].map(arr_dep_wind_deg_dict)\n","df[\"sched_arr_wind_speed\"] = df[\"id\"].map(arr_dep_wind_speed_dict)\n","df[\"sched_arr_weather_main\"] = df[\"id\"].map(arr_dep_weather_main_dict)\n","df[\"sched_arr_weather_main_desc\"] = df[\"id\"].map(arr_dep_weather_main_desc_dict)\n","\n","df.to_csv(\"flights_feature_engineering_third.csv\", index=False)\n","print(\"\\nThe dataset has been saved as 'flights_feature_engineering_third'.\")"],"metadata":{"id":"C_PwAvnYLY4L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"FX8oLET0LiYy"}},{"cell_type":"markdown","source":[],"metadata":{"id":"KQFlWeqHIWo3"}}]}